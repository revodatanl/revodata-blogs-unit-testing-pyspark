[project]
name = "unit_testing_pyspark"
version = "0.1.0"
description = "Unit testing PySpark code on Databricks"
authors = [
    { name = "RenÃ© Luijk", email = "luijk.r@gmail.com" },
]
readme = "README.md"
requires-python = ">=3.11"
dependencies = []

[tool.uv]
package = true
dev-dependencies = [
    "bandit>=1.7.10",
    "coverage>=7.6.5",
    "databricks-dlt>=0.2.1",
    "databricks-sdk>=0.37.0",
    "defusedxml>=0.7.1",
    "genbadge>=1.1.1",
    "mkdocs-material>=9.5.38",
    "mkdocs>=1.6.1",
    "mypy>=1.13.0",
    "pdoc3>=0.11.1",
    "pre-commit>=3.8.0",
    "pydoclint>=0.5.8",
    "pytest-cov>=5.0.0",
    "pytest-mock>=3.14.0",
    "pytest>=8.3.3",
    "ruff>=0.7.3",
    "sqlfluff>=3.2.5",
]

[project.scripts]
main = "unit_testing_pyspark.main:main"

[tool.ruff]
target-version = "py311"
line-length = 100
extend-include = ["*.ipynb"]
extend-exclude = ["scratch"]
builtins = ["dbutils", "display", "spark"]

[tool.ruff.lint]
pydocstyle.convention = "numpy"
external = ["DOC"]
select = ["ALL"]
ignore = [
    "D203",     # "One blank line required before class docstring." Should be disabled by default.
    "D213",     # "Multi-line docstring summary should start at the second line." Should be disabled by default.
    "E501",     # "Line too long." Sometimes my comments are a bit longer.
    "E731",     # "Do not assign a lambda expression, use a def." Needed for spark UDFs.
    "ERA001",   # "Found commented out code."
    "FBT001",   # "Boolean positional arg in function definition.
    "FBT002",   # "Boolean default value in function definition."
    "FBT003",   # "Boolean positional value in function call." This is common in spark.
    "ISC001",   # "Implicit string concatenation." Ignored since it conflicts with the formatter.
    "N812",     # "Lowercase `functions` imported as non-lowercase." Pretty standard for spark programming.
    "T201",     # "`print` found."
    # Nitpicky exceptions - comment out when productionalizing your code
    # "BLE001",   # Do not catch blind exception: `Exception`
    # "D400",     # First line should end with a period
    # "D401",     # First line of docstring should be in imperative mood
    # "PD901",    # Avoid using the generic variable name `df` for DataFrames
    # "PLR2004",  # "Magic value used in comparison, consider replacing with a constant variable."
    # "TRY003"    #  Avoid specifying long messages outside the exception class
    # Project-specific exceptions
    "S311",         # "Standard pseudo-random generators are not suitable for cryptographic purposes
    "S101",         # "Use of `assert` detected."
]
unfixable = [
    "F401",     # "Unused import." Disabled since it makes linting/formatting notebooks messy and impossible.
]

[tool.ruff.lint.per-file-ignores]
"notebooks/**/*.py" = [
    "D100",     # "Missing docstring in public module." Not needed for Databricks notebooks.
    "INP001",   # "Part of an implicit namespace package. Add an `__init__.py`." Not needed for Databricks notebooks.
]
"tests/*.py" = [
    "PLR2004",  # "Magic value used in comparison, consider replacing with a constant variable."
    "S101",     # "Use of `assert` detected."
]

[tool.mypy]
python_version = "3.11"
mypy_path = ["src"]
strict = true
disallow_untyped_decorators = false
exclude = "scratch"

[[tool.mypy.overrides]]
module = ["dlt"]
ignore_missing_imports = true

[tool.pytest.ini_options]
testpaths = ["tests"]
pythonpath = ["src"]

[tool.pydoclint]
style = "numpy"
exclude = ".git|.venv|scratch"

[tool.bandit]
targets = ["src"]
skips = [
    "B608",     # Possible SQL injection vector through string-based query construction.
]
exclude_dirs = [".venv", "archive", "scratch", "tests"]

[tool.semantic_release]
version_toml = ["pyproject.toml:project.version"]
major_on_zero = true
branch = "main"
commit_author = "github-actions[bot] <actions@github.com>"
changelog_generate = false
